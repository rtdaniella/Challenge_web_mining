{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraire le texte du pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()  # Extraire le texte de chaque page\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniella Rakotondratsimba\n",
      "6 Rue Emile Duport 69009, Lyon\n",
      "+33 7 86 62 53 12\n",
      "daniellark11@gmail.com\n",
      "Métropole de Lyon\n",
      "Lyon, le 12 Février 2025\n",
      "Objet : Candidature au poste de Stagiaire Chargé de mission Data – Data BI et Dataviz\n",
      "Madame, Monsieur,\n",
      "Actuellement en Master 2 Statistiques et Informatique pour la Science des Données (SISE) à\n",
      "l’Université Lumière Lyon 2, je suis passionnée par l’analyse et la valorisation des données. Attirée par\n",
      "les projets à impact direct sur la vie des citoyens, je souhaite rejoindre la Métropole de Lyon en tant\n",
      "que stagiaire pour participer au développement de tableaux de bord analytiques. Disponible à partir\n",
      "du 17 Mars 2025 pour une durée de 4 à 6 mois, je suis motivée à contribuer à vos initiatives\n",
      "d’innovation numérique tout en renforçant mes compétences dans un environnement dynamique et\n",
      "collaboratif.\n",
      "Durant ma formation, j’ai acquis une solide expertise en business intelligence et gestion des\n",
      "données. J’ai travaillé sur des projets impliquant la conception de tableaux de bord interactifs, la\n",
      "préparation et le traitement de données complexes, ainsi que la mise en œuvre de KPIs adaptés aux\n",
      "besoins métiers. L’utilisation d’outils tels que Power BI, SQL et des processus ETL m’a permis de\n",
      "concevoir des visualisations claires et optimisées pour faciliter la prise de décision. Ces compétences\n",
      "sont directement transposables aux missions de création, test et optimisation des tableaux de bord\n",
      "que vous proposez.\n",
      "Dotée d’un excellent sens de l’analyse, je suis également rigoureuse, curieuse et à l’aise dans\n",
      "le travail en équipe. Mon aisance relationnelle m’a permis de collaborer efficacement avec des équipes\n",
      "multidisciplinaires et de m’adapter aux enjeux spécifiques des différents métiers. Mon engagement à\n",
      "comprendre et répondre aux besoins utilisateurs me motive à accompagner la migration de vos\n",
      "tableaux existants vers DigDash et à participer à la formation des utilisateurs finaux.\n",
      "Rejoindre le service données métropolitaines de la Métropole de Lyon représente une\n",
      "opportunité idéale pour contribuer à l’amélioration des services publics grâce à des solutions de\n",
      "datavisualisation innovantes. Je serais ravie d’échanger avec vous pour vous exposer ma motivation et\n",
      "mes idées pour répondre à vos besoins.\n",
      "Dans cette attente, je vous prie d’agréer, Madame, Monsieur, l’expression de mes salutations\n",
      "distinguées.\n",
      "Cordialement,\n",
      "Daniella Rakotondratsimba\n"
     ]
    }
   ],
   "source": [
    "texte = extract_text_from_pdf(\"C:/Users/danie/OneDrive/Documents/GitHub/Challenge_web_mining/data/lm/lm_dan.pdf\")\n",
    "print(texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitrement du texte extrait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nettoyage (minuscule, ponctuation, espace multiple, chiffre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import string\n",
    "\n",
    "# def clean_text(text):\n",
    "#     # Convertir le texte en minuscules\n",
    "#     #cleaned_text = text.lower()\n",
    "    \n",
    "#     # Supprimer la ponctuation\n",
    "#     cleaned_text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "#     # Supprimer les chiffres\n",
    "#     cleaned_text = re.sub(r'\\d+', '', cleaned_text)  # Cette expression régulière supprime tous les chiffres\n",
    "    \n",
    "#     # Supprimer les espaces multiples et les remplacer par un seul espace\n",
    "#     cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    \n",
    "#     # Supprimer les espaces en début et fin de texte\n",
    "#     cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "#     return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texte_clean = clean_text(texte)\n",
    "# print(texte_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enlever les stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# # Télécharger les stopwords si ce n'est pas encore fait\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stopwords(text):\n",
    "#     stop_words = set(stopwords.words('french'))  # Liste des stopwords en français\n",
    "#     words = text.split()  # Séparer le texte en mots\n",
    "#     filtered_words = [word for word in words if word not in stop_words]  # Supprimer les stopwords\n",
    "#     return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# texte_clean = remove_stopwords(texte_clean)\n",
    "# print(texte_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction d'informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extraction lieux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# # Charger le modèle spaCy pour le français\n",
    "# nlp = spacy.load('fr_core_news_md')\n",
    "\n",
    "# def extract_places(text):\n",
    "#     doc = nlp(text)\n",
    "#     # Afficher toutes les entités extraites\n",
    "#     # for ent in doc.ents:\n",
    "#     #     print(f\"{ent.text}: {ent.label_}\")\n",
    "#     places = [ent.text for ent in doc.ents if ent.label_ == 'LOC']\n",
    "#     return places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extraction de compétence - motivation par LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Clé API Mistral (remplace par ta vraie clé)\n",
    "MISTRAL_API_KEY = \"Yp0Uo7Vx4uSJIlc94dj3MA5ME71KpwIR\"\n",
    "\n",
    "# URL de l'API Mistral\n",
    "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "\n",
    "# Fonction pour interroger Mistral et extraire des informations\n",
    "def query_mistral(prompt):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {MISTRAL_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"mistral-medium\",  # Utilise mistral-small ou mistral-large si disponible\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7  # Ajuste selon besoin\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=data)\n",
    "    \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        print(\"Erreur API :\", response.text)\n",
    "        return None\n",
    "\n",
    "# Fonction pour nettoyer la réponse de l'API et la structurer en liste\n",
    "def clean_response(response):\n",
    "    \"\"\"Nettoie la réponse en supprimant les caractères inutiles et formatant en liste.\"\"\"\n",
    "    if not response:\n",
    "        return []\n",
    "\n",
    "    # Séparer les éléments par virgule ou retour à la ligne\n",
    "    items = re.split(r',|\\n', response)\n",
    "\n",
    "    # Nettoyer les espaces et caractères spéciaux\n",
    "    cleaned_items = [item.strip() for item in items if item.strip()]\n",
    "\n",
    "    # Supprimer les doublons\n",
    "    return list(set(cleaned_items))\n",
    "\n",
    "# Fonction pour extraire les compétences\n",
    "def extract_skills(text):\n",
    "    prompt = f\"\"\"\n",
    "    Voici une lettre de motivation :\n",
    "    \"{text}\"\n",
    "\n",
    "    Extrais uniquement les compétences techniques et non techniques sous forme de liste de mots-clés sans phrases ni explication.\n",
    "    \"\"\"\n",
    "    return query_mistral(prompt)\n",
    "\n",
    "# Fonction pour extraire les motivations\n",
    "def extract_motivations(text):\n",
    "    prompt = f\"\"\"\n",
    "    Voici une lettre de motivation :\n",
    "    \"{text}\"\n",
    "\n",
    "    Extrais uniquement les motivations du candidat sous forme de liste de mots-clés sans phrases ni explication.\n",
    "    \"\"\"\n",
    "    return query_mistral(prompt)\n",
    "\n",
    "# Fonction pour extraire le lieu de disponibilité\n",
    "def extract_location(text):\n",
    "    prompt = f\"\"\"\n",
    "    Voici une lettre de motivation :\n",
    "    \"{text}\"\n",
    "\n",
    "    Identifie et retourne uniquement le nom du lieu où le candidat indique être disponible pour travailler, sans phrase ni explication.\n",
    "    \"\"\"\n",
    "    return query_mistral(prompt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Response is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[145]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m skills = \u001b[43mextract_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexte\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Compétences :\u001b[39m\u001b[33m\"\u001b[39m, skills)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mextract_skills\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_skills\u001b[39m(text):\n\u001b[32m     53\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[33m    Voici une lettre de motivation :\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m \u001b[33m    Extrais uniquement les compétences techniques et non techniques sous forme de liste de mots-clés sans phrases ni explication.\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_mistral\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mquery_mistral\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     26\u001b[39m response = requests.post(API_URL, headers=headers, json=data)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Convertir la réponse en une chaîne JSON\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m json_response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\anaconda3\\envs\\ocrcvlm\\Lib\\json\\__init__.py:231\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    228\u001b[39m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    230\u001b[39m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\anaconda3\\envs\\ocrcvlm\\Lib\\json\\encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\anaconda3\\envs\\ocrcvlm\\Lib\\json\\encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\anaconda3\\envs\\ocrcvlm\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type Response is not JSON serializable"
     ]
    }
   ],
   "source": [
    "skills = extract_skills(texte)\n",
    "print(\"✅ Compétences :\", skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Motivations : 1. Passionnée par l'analyse et la valorisation des données\n",
      "2. Projets à impact direct sur la vie des citoyens\n",
      "3. Stagiaire pour participer au développement de tableaux de bord analytiques\n",
      "4. Contribuer à vos initiatives d’innovation numérique\n",
      "5. Renforcer ses compétences dans un environnement dynamique et collaboratif\n",
      "6. Solide expertise en business intelligence et gestion des données\n",
      "7. Conception de tableaux de bord interactifs\n",
      "8. Préparation et traitement de données complexes\n",
      "9. Mise en œuvre de KPIs adaptés aux besoins métiers\n",
      "10. Utilisation d’outils tels que Power BI, SQL et des processus ETL\n",
      "11. Concevoir des visualisations claires et optimisées pour faciliter la prise de décision\n",
      "12. Excellent sens de l’analyse\n",
      "13. Rigoureuse, curieuse et à l’aise dans le travail en équipe\n",
      "14. Aisance relationnelle\n",
      "15. Collaborer efficacement avec des équipes multidisciplinaires\n",
      "16. Adapter aux enjeux spécifiques des différents métiers\n",
      "17. Engagement à comprendre et répondre aux besoins utilisateurs\n",
      "18. Accompagner la migration de vos tableaux existants vers DigDash\n",
      "19. Participer à la formation des utilisateurs finaux\n",
      "20. Contribuer à l’amélioration des services publics grâce à des solutions de datavisualisation innovantes.\n"
     ]
    }
   ],
   "source": [
    "motivations = extract_motivations(texte)\n",
    "print(\"✅ Motivations :\", motivations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📍 Localisation : Lyon\n",
      "\n",
      "Note: The candidate mentions that they want to join the Métropole de Lyon, which suggests they are available to work in Lyon. However, the exact location within Lyon is not specified. Therefore, I have returned \"Lyon\" as the place where the candidate is available to work. If you need more specific information, please let me know.\n"
     ]
    }
   ],
   "source": [
    "location = extract_location(texte)\n",
    "print(\"📍 Localisation :\", location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertion dans la bdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Configuration de la connexion PostgreSQL\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"cv_lm_db\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"daniella\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Ouvre une connexion à PostgreSQL.\"\"\"\n",
    "    return psycopg2.connect(**DB_CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enregistrer les données du LM dans la bdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_competences(competences):\n",
    "    \"\"\"Insère des compétences dans la table des compétences.\"\"\"\n",
    "    connection = get_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        # Format des compétences en un tableau\n",
    "        competences_list = competences.split('\\n')  # Supposons que vous sépariez par ligne\n",
    "        formatted_competences = '{' + ','.join(competences_list) + '}'\n",
    "\n",
    "        # Insertion du tableau\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO competences (competences)\n",
    "        VALUES (%s)\n",
    "        \"\"\", (formatted_competences,))\n",
    "        \n",
    "        # Commit les changements\n",
    "        connection.commit()\n",
    "        print(\"Compétences insérées avec succès.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'insertion des compétences : {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'insertion des compétences : ERREUR:  tableau litéral mal formé : « {Compétences techniques :,,* Business intelligence,* Gestion de données,* Conception de tableaux de bord interactifs,* Préparation de données,* Traitement de données complexes,* Mise en œuvre de KPIs,* Power BI,* SQL,* Processus ETL,* Visualisations de données,* Migration de tableaux de bord,* Formation d'utilisateurs finaux,,Compétences non techniques :,,* Sens de l'analyse,* Rigueur,* Curiosité,* Travail en équipe,* Aisance relationnelle,* Adaptabilité,* Engagement utilisateur} »\n",
      "LINE 3:         VALUES ('{Compétences techniques :,,* Business intel...\n",
      "                        ^\n",
      "DETAIL:  Caractère « , » inattendu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert_competences(skills)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrcvlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
