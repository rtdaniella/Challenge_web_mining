{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "try:\n",
    "    import pyarrow\n",
    "except:\n",
    "    %pip install pyarrow\n",
    "    import pyarrow\n",
    "try:\n",
    "    import bs4\n",
    "    from bs4 import BeautifulSoup\n",
    "except:\n",
    "    %pip install beautifulsoup4\n",
    "    import bs4\n",
    "    from bs4 import BeautifulSoup\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    %pip install pandas\n",
    "    import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 AppleWebKit/605.1.15 Version/17.4.1 Safari/605.1.15\",\n",
    "    #    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8\",\n",
    "        \"Accept-Language\": \"fr-FR,fr;q=0.8\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Cache-Control\": \"max-age=0\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8', 'Accept-Language': 'fr-FR,fr;q=0.8', 'Accept-Encoding': 'gzip, deflate', 'Connection': 'keep-alive', 'Upgrade-Insecure-Requests': '1', 'Sec-Fetch-Mode': 'navigate', 'Sec-Fetch-Site': 'none', 'Sec-Fetch-User': '?1', 'Cache-Control': 'max-age=0'}\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0\",  # Updated\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8\",\n",
    "    \"Accept-Language\": \"fr-FR,fr;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"none\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "}\n",
    "\n",
    "# Optionally remove an existing header\n",
    "del headers[\"Sec-Fetch-Dest\"]\n",
    "\n",
    "print(headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_soup(soup: bs4.BeautifulSoup):\n",
    "    competences = []\n",
    "    annonce = dict()\n",
    "\n",
    "    annonce[\"intitule_poste\"] = soup.find(\"span\", {\"itemprop\": \"title\"}).text\n",
    "    annonce[\"description\"] = soup.find(\"div\", {\"itemprop\": \"description\"}).text\n",
    "    annonce[\"experience\"] = soup.find(\"span\", {\"itemprop\": \"experienceRequirements\"}).text\n",
    "\n",
    "    skill = soup.select(\"ul.skill-list.list-unstyled > li\")\n",
    "    for item in skill:\n",
    "        exp = item.find_all(\"span\", {\"itemprop\": \"experienceRequirements\"})\n",
    "        educ = item.find_all(\"span\", {\"itemprop\": \"educationRequirements\"})\n",
    "        comp = item.find(\"span\", {\"class\": \"skill skill-competence\"})\n",
    "        sav = item.find(\"span\", {\"class\": \"skill skill-savoir\"})\n",
    "        lang = item.find(\"span\", {\"class\": \"skill skill-langue\"})\n",
    "        perm = item.find(\"span\", {\"class\": \"skill skill-permis\"})\n",
    "        if len(exp) != 0:\n",
    "            experience = exp[0].text\n",
    "            exp_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            annonce[\"experience\"] = (experience, exp_requis)\n",
    "        if educ:\n",
    "            education = educ[0].text\n",
    "            educ_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            annonce[\"education\"] = (education, educ_requis)\n",
    "        if lang:\n",
    "            langue = lang.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            langue_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append((langue, langue_requis))\n",
    "        if perm:\n",
    "            permis = item.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            permis_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append((permis, permis_requis))\n",
    "        if comp:\n",
    "            competence = comp.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            requis = True if comp.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append((competence, requis))\n",
    "        if sav:\n",
    "            savoir = sav.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            requis = True if sav.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append((savoir, requis))\n",
    "    annonce[\"competences\"] = competences\n",
    "    infos = soup.find(\"div\", {\"class\": \"description-aside col-sm-4 col-md-5\"}).select(\"dd\")\n",
    "    divers = [item.text for item in infos[2:]]\n",
    "    annonce[\"divers\"] = divers\n",
    "    return annonce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- corriger l'auto-increment de id en cas de conflit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "def to_db(annonce: dict):\n",
    "    # Connexion à la base de données PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"webmining\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgres\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for comp in annonce[\"competences\"]:\n",
    "        if isinstance(comp, str):\n",
    "            competence = comp\n",
    "            requis = False\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO competences (nom, requis)\n",
    "                VALUES (%s, %s)\n",
    "                ON CONFLICT (nom) DO NOTHING;\n",
    "            \"\"\", (competence, requis))\n",
    "        else:\n",
    "            # Insertion des données dans la table postes\n",
    "            # Insert competences (if not already inserted)\n",
    "            for competence, requis in comp:\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO competences (nom, requis)\n",
    "                    VALUES (%s, %s)\n",
    "                    ON CONFLICT (nom) DO NOTHING;\n",
    "                \"\"\", (competence, requis))\n",
    "\n",
    "    # Insert postes (job positions)\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO annonces (intitule_poste, description, experience, divers, reference)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        RETURNING reference;\n",
    "    \"\"\", (annonce[\"intitule_poste\"], annonce[\"description\"], annonce[\"experience\"], annonce[\"divers\"], annonce[\"reference\"]))\n",
    "    \n",
    "    # print(cur.fetchone())\n",
    "    annonce_id = cur.fetchone()[0]\n",
    "    print(annonce_id)\n",
    "\n",
    "    for comp in annonce[\"competences\"]:\n",
    "        if isinstance(comp, str):\n",
    "            competence = comp\n",
    "            cur.execute(\"\"\"\n",
    "            INSERT INTO annonce_competences (annonce_reference, competence_id)\n",
    "            SELECT %s, id FROM competences WHERE nom = %s;\n",
    "            \"\"\", (annonce_id, competence))\n",
    "        else:\n",
    "            for competence, requis in annonce[\"competences\"]:\n",
    "                # Insert relationship into the junction table\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO annonce_competences (annonce_reference, competence_id)\n",
    "                    SELECT %s, id FROM competences WHERE nom = %s;\n",
    "                \"\"\", (annonce_id, competence))\n",
    "\n",
    "\n",
    "    # Validation des modifications et fermeture de la connexion\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mots clés:\n",
    "- data engineer\n",
    "- data analyst\n",
    "- data scientist\n",
    "- big data\n",
    "- IA\n",
    "- architecte cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    urls = []\n",
    "    with open(\"urls.txt\", \"r\") as f:\n",
    "        urls = [line.replace(\"\\n\", \"\") for line in f]\n",
    "except:\n",
    "    urls = []\n",
    "    offre_FT = [\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?motsCles=data+engineer&offresPartenaires=true&rayon=10&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?lieux=69381&motsCles=data+analyst&offresPartenaires=true&rayon=30&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?lieux=69381&motsCles=data+scientist&offresPartenaires=true&range=0-19&rayon=30&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?lieux=69381&motsCles=big+data&offresPartenaires=true&rayon=30&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?motsCles=intelligence+artificielle&offresPartenaires=true&rayon=10&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?motsCles=architecte+cloud&offresPartenaires=true&rayon=10&tri=0\"]\n",
    "\n",
    "    for url in offre_FT:\n",
    "        while True:\n",
    "            r = requests.get(url, headers= headers)\n",
    "            if r.status_code != 200:\n",
    "                print(\"waiting 5s\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            soup = BeautifulSoup(r.text)\n",
    "            urls = urls + [link.get(\"href\") for link in soup.select('ul[data-container-type=\"zone\"] > li > a')]\n",
    "            time.sleep(2)\n",
    "            break\n",
    "    with open(\"urls.txt\", \"w\") as f:\n",
    "        for url in urls:\n",
    "            f.write(url+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efface toutes les tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def clear_db():\n",
    "    conn_params = {\n",
    "        \"dbname\": \"webmining\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"postgres\",\n",
    "        \"host\": \"localhost\",  # Change to 'my_postgres_container' if using Docker\n",
    "        \"port\": \"5432\"\n",
    "    }\n",
    "\n",
    "    drop_tables_sql = \"\"\"\n",
    "        DROP TABLE IF EXISTS annonce_competences;\n",
    "        DROP TABLE IF EXISTS competences;\n",
    "        DROP TABLE IF EXISTS annonces;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with psycopg2.connect(**conn_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(drop_tables_sql)\n",
    "                print(\"Tables dropped successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error dropping tables:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crée les tables à partir du fichier db_webmining.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "def make_table():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"webmining\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgres\",\n",
    "        host=\"localhost\",  # Change if using Docker\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "\n",
    "    # Table creation queries\n",
    "    with open(\"db_webmining.sql\", \"r\") as f:\n",
    "        create_tables_sql = f.read()\n",
    "\n",
    "    cur.execute(create_tables_sql)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"✅ Tables created successfully!\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "domaine = \"https://candidat.francetravail.fr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.8\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Host\": \"candidat.francetravail.fr\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Sec-GPC\": \"1\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\",\n",
    "    \"sec-ch-ua\": '\"Chromium\";v=\"134\", \"Not:A-Brand\";v=\"24\", \"Brave\";v=\"134\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": '\"Windows\"',\n",
    "}\n",
    "\n",
    "cookies = {\n",
    "    \"TCPID\": \"125331445152517760379\",\n",
    "    \"dtCookie\": \"v_4_srv_8_sn_A03B54816D5AF0755CC6317FD915D035_perc_100000_ol_0_mul_1_app-3A6e350f5c3735afd9_1_rcs-3Acss_0\",\n",
    "    \"BIGipServerPOOL_PWNOT-00PT28_HTTPS_PN055-VIPA_3_PN055\": \"2940013066.56131.0000\",\n",
    "    \"TS016fc3b0\": \"0150c672c31d6f6c7a73fc28f33de8c9cb7dc5105bab64f0d4292f3e76519df0c24f2cfae5e0d5cb90ff9f7ca9259859d850aa9eed\",\n",
    "    \"JSESSIONID_RECH_OFFRE\": \"6HqNhHJ-DbDp_Y5VWI_-YG5oCPFoFAzpLXQmdlZ8YZenhh6JuYLm!-292444737\",\n",
    "    \"userBadge\": \"0\",\n",
    "}\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./urls.txt\", \"w\") as f:\n",
    "    f.writelines(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://candidat.francetravail.fr/offres/recherche/detail/3487041'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domaine + str(urls[i]).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tables dropped successfully!\n",
      "✅ Tables created successfully!\n",
      "/offres/recherche/detail/189KZNQ\n",
      "189KZNQ\n",
      "/offres/recherche/detail/189GQNP\n",
      "189GQNP\n",
      "/offres/recherche/detail/189GJVT\n",
      "189GJVT\n",
      "/offres/recherche/detail/188ZWDF\n",
      "188ZWDF\n",
      "/offres/recherche/detail/188ZDGF\n",
      "188ZDGF\n",
      "/offres/recherche/detail/188VWGG\n",
      "188VWGG\n",
      "/offres/recherche/detail/188SXMM\n",
      "188SXMM\n",
      "/offres/recherche/detail/188HLBS\n",
      "188HLBS\n",
      "/offres/recherche/detail/188HFWY\n",
      "188HFWY\n",
      "/offres/recherche/detail/188GHTY\n",
      "188GHTY\n",
      "/offres/recherche/detail/188DDRG\n",
      "188DDRG\n",
      "/offres/recherche/detail/187NTTM\n",
      "187NTTM\n",
      "/offres/recherche/detail/186RJZQ\n",
      "186RJZQ\n",
      "/offres/recherche/detail/189DCYW\n",
      "189DCYW\n",
      "/offres/recherche/detail/188RQRZ\n",
      "188RQRZ\n",
      "/offres/recherche/detail/189KVTX\n",
      "189KVTX\n",
      "/offres/recherche/detail/189KVNN\n",
      "189KVNN\n",
      "/offres/recherche/detail/189JDYT\n",
      "189JDYT\n",
      "/offres/recherche/detail/189CBPG\n",
      "189CBPG\n",
      "/offres/recherche/detail/188ZVFK\n",
      "188ZVFK\n",
      "/offres/recherche/detail/189KBNV\n",
      "189KBNV\n",
      "/offres/recherche/detail/188QRMV\n",
      "188QRMV\n",
      "/offres/recherche/detail/3408437\n",
      "3408437\n",
      "/offres/recherche/detail/3399091\n",
      "3399091\n",
      "/offres/recherche/detail/3447143\n",
      "3447143\n",
      "/offres/recherche/detail/3402073\n",
      "3402073\n",
      "/offres/recherche/detail/3371543\n",
      "3371543\n",
      "/offres/recherche/detail/3371984\n",
      "3371984\n",
      "/offres/recherche/detail/3365220\n",
      "3365220\n",
      "/offres/recherche/detail/3240609\n",
      "3240609\n",
      "/offres/recherche/detail/3173480\n",
      "3173480\n",
      "/offres/recherche/detail/3152053\n",
      "3152053\n",
      "/offres/recherche/detail/3178443\n",
      "3178443\n",
      "/offres/recherche/detail/3073947\n",
      "3073947\n",
      "/offres/recherche/detail/2994992\n"
     ]
    }
   ],
   "source": [
    "clear_db()\n",
    "make_table()\n",
    "j=0\n",
    "for i in range(0,len(urls), 2):\n",
    "    print(urls[i])\n",
    "    r = session.get(url=domaine + str(urls[i]).replace(\"\\n\", \"\"), cookies=cookies)\n",
    "    if r.status_code != 200:\n",
    "        break\n",
    "    soup = BeautifulSoup(r.text)  \n",
    "    annonce = parse_soup(soup)\n",
    "    annonce[\"reference\"] = urls[i].split(\"/\")[-1]\n",
    "    to_db(annonce)\n",
    "    j+=1\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restauration de la bdd depuis les fichiers json individuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annonces = []\n",
    "files = os.listdir(\"./json\")\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    annonce = {}\n",
    "    with open(\"./json/\"+file, \"r\") as f:\n",
    "        doc = json.load(f)\n",
    "\n",
    "    annonce[\"reference\"] = doc[\"reference\"]\n",
    "    annonce[\"intitule_poste\"] = doc[\"intitule_poste\"]\n",
    "    annonce[\"description\"] = doc[\"description\"]\n",
    "    annonce[\"divers\"] = \" \".join(doc[\"divers\"])\n",
    "    annonce[\"experience\"] = doc[\"experience\"][0]\n",
    "    annonce[\"competences\"] = [competence if isinstance(competence, str) else competence[0] for competence in doc[\"competences\"]]\n",
    "    annonces.append(annonce)\n",
    "\n",
    "clear_db()\n",
    "make_table()\n",
    "for annonce in annonces:\n",
    "    print(annonce[\"reference\"])\n",
    "    to_db(annonce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export de la bdd en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table annonce_competences saved to annonce_competences.csv\n",
      "Table competences saved to competences.csv\n",
      "Table annonces saved to annonces.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_8620\\2618511829.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"webmining\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query to get table names\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "for table in tables:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "    df.to_csv(f\"{table}.csv\", index=False)\n",
    "    print(f\"Table {table} saved to {table}.csv\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
