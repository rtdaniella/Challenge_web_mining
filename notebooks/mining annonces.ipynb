{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "try:\n",
    "    import pyarrow\n",
    "except:\n",
    "    %pip install pyarrow\n",
    "    import pyarrow\n",
    "try:\n",
    "    import bs4\n",
    "    from bs4 import BeautifulSoup\n",
    "except:\n",
    "    %pip install beautifulsoup4\n",
    "    import bs4\n",
    "    from bs4 import BeautifulSoup\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    %pip install pandas\n",
    "    import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 AppleWebKit/605.1.15 Version/17.4.1 Safari/605.1.15\",\n",
    "    #    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8\",\n",
    "        \"Accept-Language\": \"fr-FR,fr;q=0.8\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Cache-Control\": \"max-age=0\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8', 'Accept-Language': 'fr-FR,fr;q=0.8', 'Accept-Encoding': 'gzip, deflate', 'Connection': 'keep-alive', 'Upgrade-Insecure-Requests': '1', 'Sec-Fetch-Mode': 'navigate', 'Sec-Fetch-Site': 'none', 'Sec-Fetch-User': '?1', 'Cache-Control': 'max-age=0'}\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0\",  # Updated\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,/;q=0.8\",\n",
    "    \"Accept-Language\": \"fr-FR,fr;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"none\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "}\n",
    "\n",
    "# Optionally remove an existing header\n",
    "del headers[\"Sec-Fetch-Dest\"]\n",
    "\n",
    "print(headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_soup(soup: bs4.BeautifulSoup):\n",
    "    competences = []\n",
    "    annonce = dict()\n",
    "\n",
    "    annonce[\"intitule_poste\"] = soup.find(\"span\", {\"itemprop\": \"title\"}).text\n",
    "    annonce[\"description\"] = soup.find(\"div\", {\"itemprop\": \"description\"}).text\n",
    "    annonce[\"experience\"] = soup.find(\"span\", {\"itemprop\": \"experienceRequirements\"}).text\n",
    "\n",
    "    skill = soup.select(\"ul.skill-list.list-unstyled > li\")\n",
    "    for item in skill:\n",
    "        exp = item.find_all(\"span\", {\"itemprop\": \"experienceRequirements\"})\n",
    "        educ = item.find_all(\"span\", {\"itemprop\": \"educationRequirements\"})\n",
    "        comp = item.find(\"span\", {\"class\": \"skill skill-competence\"})\n",
    "        sav = item.find(\"span\", {\"class\": \"skill skill-savoir\"})\n",
    "        lang = item.find(\"span\", {\"class\": \"skill skill-langue\"})\n",
    "        perm = item.find(\"span\", {\"class\": \"skill skill-permis\"})\n",
    "        if len(exp) != 0:\n",
    "            experience = exp[0].text\n",
    "            exp_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            annonce[\"experience\"] = (experience, exp_requis)\n",
    "        if educ:\n",
    "            education = educ[0].text\n",
    "            educ_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            annonce[\"education\"] = education\n",
    "        if lang:\n",
    "            langue = lang.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            langue_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append(langue)\n",
    "        if perm:\n",
    "            permis = item.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            permis_requis = True if item.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append(permis)\n",
    "        if comp:\n",
    "            competence = comp.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            requis = True if comp.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append(competence)\n",
    "        if sav:\n",
    "            savoir = sav.find(\"span\", {\"class\": \"skill-name\"}).text\n",
    "            requis = True if sav.find(\"span\", {\"class\": \"skill-required\"}) else False\n",
    "            competences.append(savoir)\n",
    "    annonce[\"competences\"] = competences\n",
    "    infos = soup.find(\"div\", {\"class\": \"description-aside col-sm-4 col-md-5\"}).select(\"dd\")\n",
    "    divers = [item.text for item in infos[2:]]\n",
    "    annonce[\"divers\"] = divers\n",
    "    return annonce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- corriger l'auto-increment de id en cas de conflit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "def to_db(annonce: dict):\n",
    "    # Connexion à la base de données PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"webmining\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgres\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for competence in annonce[\"competences\"]:\n",
    "        if isinstance(comp, str):\n",
    "            competence = comp\n",
    "            requis = False\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO competences (nom)\n",
    "                VALUES (%s)\n",
    "                ON CONFLICT (nom) DO NOTHING;\n",
    "            \"\"\", (competence))\n",
    "\n",
    "    # Insert postes (job positions)\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO annonces (intitule_poste, description, experience, divers, reference)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        RETURNING reference;\n",
    "    \"\"\", (annonce[\"intitule_poste\"], annonce[\"description\"], annonce[\"experience\"], annonce[\"divers\"], annonce[\"reference\"]))\n",
    "    \n",
    "    # print(cur.fetchone())\n",
    "    annonce_id = cur.fetchone()[0]\n",
    "    print(annonce_id)\n",
    "\n",
    "    for comp in annonce[\"competences\"]:\n",
    "        if isinstance(comp, str):\n",
    "            competence = comp\n",
    "            cur.execute(\"\"\"\n",
    "            INSERT INTO annonce_competences (annonce_reference, competence_id)\n",
    "            SELECT %s, id FROM competences WHERE nom = %s;\n",
    "            \"\"\", (annonce_id, competence))\n",
    "        else:\n",
    "            for competence, requis in annonce[\"competences\"]:\n",
    "                # Insert relationship into the junction table\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO annonce_competences (annonce_reference, competence_id)\n",
    "                    SELECT %s, id FROM competences WHERE nom = %s;\n",
    "                \"\"\", (annonce_id, competence))\n",
    "\n",
    "\n",
    "    # Validation des modifications et fermeture de la connexion\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mots clés:\n",
    "- data engineer\n",
    "- data analyst\n",
    "- data scientist\n",
    "- big data\n",
    "- IA\n",
    "- architecte cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    urls = []\n",
    "    with open(\"urls.txt\", \"r\") as f:\n",
    "        urls = [line.replace(\"\\n\", \"\") for line in f]\n",
    "except:\n",
    "    urls = []\n",
    "    offre_FT = [\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?motsCles=data+engineer&offresPartenaires=true&rayon=10&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?lieux=69381&motsCles=data+analyst&offresPartenaires=true&rayon=30&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?lieux=69381&motsCles=data+scientist&offresPartenaires=true&range=0-19&rayon=30&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?lieux=69381&motsCles=big+data&offresPartenaires=true&rayon=30&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?motsCles=intelligence+artificielle&offresPartenaires=true&rayon=10&tri=0\",\n",
    "        \"https://candidat.francetravail.fr/offres/recherche?motsCles=architecte+cloud&offresPartenaires=true&rayon=10&tri=0\"]\n",
    "\n",
    "    for url in offre_FT:\n",
    "        while True:\n",
    "            r = requests.get(url, headers= headers)\n",
    "            if r.status_code != 200:\n",
    "                print(\"waiting 5s\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            soup = BeautifulSoup(r.text)\n",
    "            urls = urls + [link.get(\"href\") for link in soup.select('ul[data-container-type=\"zone\"] > li > a')]\n",
    "            time.sleep(2)\n",
    "            break\n",
    "    with open(\"urls.txt\", \"w\") as f:\n",
    "        for url in urls:\n",
    "            f.write(url+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efface toutes les tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def clear_db():\n",
    "    conn_params = {\n",
    "        \"dbname\": \"webmining\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"postgres\",\n",
    "        \"host\": \"localhost\",  # Change to 'my_postgres_container' if using Docker\n",
    "        \"port\": \"5432\"\n",
    "    }\n",
    "\n",
    "    drop_tables_sql = \"\"\"\n",
    "        DROP TABLE IF EXISTS annonce_competences;\n",
    "        DROP TABLE IF EXISTS competences;\n",
    "        DROP TABLE IF EXISTS annonces;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with psycopg2.connect(**conn_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(drop_tables_sql)\n",
    "                print(\"Tables dropped successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error dropping tables:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crée les tables à partir du fichier db_webmining.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "def make_table():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"webmining\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgres\",\n",
    "        host=\"localhost\",  # Change if using Docker\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "\n",
    "    # Table creation queries\n",
    "    with open(\"db_webmining.sql\", \"r\") as f:\n",
    "        create_tables_sql = f.read()\n",
    "\n",
    "    cur.execute(create_tables_sql)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"✅ Tables created successfully!\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "domaine = \"https://candidat.francetravail.fr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.8\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Host\": \"candidat.francetravail.fr\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Sec-GPC\": \"1\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36\",\n",
    "    \"sec-ch-ua\": '\"Chromium\";v=\"134\", \"Not:A-Brand\";v=\"24\", \"Brave\";v=\"134\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": '\"Windows\"',\n",
    "}\n",
    "\n",
    "cookies = {\n",
    "    \"TCPID\": \"125331445152517760379\",\n",
    "    \"dtCookie\": \"v_4_srv_8_sn_A03B54816D5AF0755CC6317FD915D035_perc_100000_ol_0_mul_1_app-3A6e350f5c3735afd9_1_rcs-3Acss_0\",\n",
    "    \"BIGipServerPOOL_PWNOT-00PT28_HTTPS_PN055-VIPA_3_PN055\": \"2940013066.56131.0000\",\n",
    "    \"TS016fc3b0\": \"0150c672c31d6f6c7a73fc28f33de8c9cb7dc5105bab64f0d4292f3e76519df0c24f2cfae5e0d5cb90ff9f7ca9259859d850aa9eed\",\n",
    "    \"JSESSIONID_RECH_OFFRE\": \"6HqNhHJ-DbDp_Y5VWI_-YG5oCPFoFAzpLXQmdlZ8YZenhh6JuYLm!-292444737\",\n",
    "    \"userBadge\": \"0\",\n",
    "}\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./urls.txt\", \"w\") as f:\n",
    "    f.writelines(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://candidat.francetravail.fr/offres/recherche/detail/2994992'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domaine + str(urls[i]).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tables dropped successfully!\n",
      "✅ Tables created successfully!\n",
      "/offres/recherche/detail/189KZNQ\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m annonce = parse_soup(soup)\n\u001b[32m     11\u001b[39m annonce[\u001b[33m\"\u001b[39m\u001b[33mreference\u001b[39m\u001b[33m\"\u001b[39m] = urls[i].split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mto_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannonce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m j+=\u001b[32m1\u001b[39m\n\u001b[32m     14\u001b[39m time.sleep(\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[162]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mto_db\u001b[39m\u001b[34m(annonce)\u001b[39m\n\u001b[32m     17\u001b[39m         cur.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[33m            INSERT INTO competences (nom, requis)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m            VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m            ON CONFLICT (nom) DO NOTHING;\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m, (competence, requis))\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     23\u001b[39m         \u001b[38;5;66;03m# Insertion des données dans la table postes\u001b[39;00m\n\u001b[32m     24\u001b[39m         \u001b[38;5;66;03m# Insert competences (if not already inserted)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m competence, requis \u001b[38;5;129;01min\u001b[39;00m comp:\n\u001b[32m     26\u001b[39m             cur.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m                INSERT INTO competences (nom, requis)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33m                VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m                ON CONFLICT (nom) DO NOTHING;\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m            \u001b[39m\u001b[33m\"\"\"\u001b[39m, (competence, requis))\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Insert postes (job positions)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "clear_db()\n",
    "make_table()\n",
    "j=0\n",
    "for i in range(0,len(urls), 2):\n",
    "    print(urls[i])\n",
    "    r = session.get(url=domaine + str(urls[i]).replace(\"\\n\", \"\"), cookies=cookies)\n",
    "    if r.status_code != 200:\n",
    "        break\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    annonce = parse_soup(soup)\n",
    "    annonce[\"reference\"] = urls[i].split(\"/\")[-1]\n",
    "    to_db(annonce)\n",
    "    j+=1\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intitule_poste': 'Data engineer (H/F)',\n",
       " 'description': \"IONE Talents & Technology, société de Conseil en Système d'Information avec une forte expertise métier créée par un expert dans le domaine de la data, IONE Talents & Technology c'est surtout un ensemble de consultant.e.s capables d'intervenir à tous les niveaux d'un Système d'Information.\\n\\nSi vous souhaitez rejoindre une entreprise à taille humaine où chaque employé peut avoir un réel rôle à jouer dans son développement, vous êtes au bon endroit.\\n\\nDans le cadre de notre croissance sur la région d'ile de France, nous recrutons actuellement un(e) Data engineer IT en CDI pour pour intervenir chez nos clients dans la mise en place de nouveaux projets.\\n\\n\\nProfil recherché : \\n- Expérience significative dans un environnement Cloud (AWS, Azure, GCP) \\n- Pratique confirmée des méthodes Agiles \\n Compétences techniques \\n- Maîtrise des langages de programmation : Python 3, Scala, Spark \\n- Expertise en technologies Big Data : Hadoop, Kafka, Hive \\n- Expérience approfondie des bases de données SQL et NoSQL : PostgreSQL, MongoDB, Cassandra \\n- Maîtrise des outils DevOps : Docker, Git, Kubernetes (AKS) \\n- Expérience en visualisation de données : Power BI, Tableau, Jupyter \\n- La connaissance de Streamlit/Dash et des outils d'infrastructure as code (Terraform, Ansible) est un plus \\n- Curiosité intellectuelle et passion pour le traitement des données massives \\n- Excellentes capacités de communication en français et en anglais \\n- Aptitude à travailler dans un environnement international\\n- Maîtrise d'un ou plusieurs outils d'alimentation ETL (SSIS,Talend.),\\n\\nAu-delà de votre formation et de votre expertise, nous recherchons de futurs collaborateurs motivés par la perspective d'intégrer une structure à taille humaine en pleine croissance, exigeante et favorisant l'esprit d'équipe.\",\n",
       " 'experience': ('Débutant accepté', False),\n",
       " 'education': (\"Bac+5 et plus ou équivalents informatique et systèmes d'information\\n\",\n",
       "  True),\n",
       " 'competences': [('Actualiser régulièrement ses connaissances', True),\n",
       "  ('Adapter les méthodes de travail à la réglementation locale', True),\n",
       "  ('Algorithmique', True),\n",
       "  (\"Analyser / traiter l'information à des fins d'anticipation\", True),\n",
       "  ('Analyser, exploiter, structurer des données', True),\n",
       "  ('Anglais technique', True),\n",
       "  ('Business Intelligence (BI) / Informatique décisionnelle', True),\n",
       "  ('Collaborer dans un groupe pour réaliser un projet', True),\n",
       "  (\"Communiquer à l'écrit de façon appropriée\", True),\n",
       "  ('Concevoir et gérer un projet', True),\n",
       "  ('Convaincre en argumentant avec un ou plusieurs interlocuteurs (interne et externe)',\n",
       "   True),\n",
       "  ('Data engineer', True),\n",
       "  ('Définir les solutions de stockage et de structuration des données', True),\n",
       "  ('Déploiement de services cloud (cloud computing)', True),\n",
       "  (\"Déployer, intégrer un logiciel, un système d'informations, une application\",\n",
       "   True),\n",
       "  ('Développer une application en lien avec une base de données', True),\n",
       "  ('Enrichir une base de données', True),\n",
       "  ('Expliquer et faire respecter les règles et procédures', True),\n",
       "  ('Gérer et maitriser des bases de données (SQL/NoSQL)', True),\n",
       "  ('Gérer une architecture technique', True),\n",
       "  ('Identifier ses axes de progrès', True),\n",
       "  ('Informatique scientifique et technique', True),\n",
       "  (\"Mettre en place des solutions d'amélioration de la performance\", True),\n",
       "  ('Modéliser une base de données', True),\n",
       "  ('Programmation en Python', True),\n",
       "  ('Recueillir et analyser les besoins client', True),\n",
       "  ('Réaliser une analyse ou modélisation statistique de données', True),\n",
       "  ('Technologies HADOOP', True),\n",
       "  ('Technologies SPARK (Framework)', True),\n",
       "  (\"Tester un logiciel, un système d'informations, une application\", True),\n",
       "  ('Vérifier la compatibilité des développements produits avec les spécifications',\n",
       "   True),\n",
       "  ('Anglais', True),\n",
       "  ('B - Véhicule léger', False)],\n",
       " 'divers': ['Salaire brut : Selon Expérience',\n",
       "  'Déplacements\\xa0: Quotidiens Zone nationale'],\n",
       " 'reference': '189KZNQ'}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annonce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restauration de la bdd depuis les fichiers json individuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annonces = []\n",
    "files = os.listdir(\"./json\")\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    annonce = {}\n",
    "    with open(\"./json/\"+file, \"r\") as f:\n",
    "        doc = json.load(f)\n",
    "\n",
    "    annonce[\"reference\"] = doc[\"reference\"]\n",
    "    annonce[\"intitule_poste\"] = doc[\"intitule_poste\"]\n",
    "    annonce[\"description\"] = doc[\"description\"]\n",
    "    annonce[\"divers\"] = \" \".join(doc[\"divers\"])\n",
    "    annonce[\"experience\"] = doc[\"experience\"][0]\n",
    "    annonce[\"competences\"] = [competence if isinstance(competence, str) else competence[0] for competence in doc[\"competences\"]]\n",
    "    annonces.append(annonce)\n",
    "\n",
    "clear_db()\n",
    "make_table()\n",
    "for annonce in annonces:\n",
    "    print(annonce[\"reference\"])\n",
    "    to_db(annonce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export de la bdd en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table annonce_competences saved to annonce_competences.csv\n",
      "Table competences saved to competences.csv\n",
      "Table annonces saved to annonces.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_8620\\2618511829.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"webmining\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query to get table names\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "for table in tables:\n",
    "    df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "    df.to_csv(f\"{table}.csv\", index=False)\n",
    "    print(f\"Table {table} saved to {table}.csv\")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[174]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m         cur.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m            INSERT INTO competences (nom, requis)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m            VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m            ON CONFLICT (nom) DO NOTHING;\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m, (competence, requis))\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     20\u001b[39m         \u001b[38;5;66;03m# Insertion des données dans la table postes\u001b[39;00m\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# Insert competences (if not already inserted)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m competence, requis \u001b[38;5;129;01min\u001b[39;00m comp:\n\u001b[32m     23\u001b[39m             cur.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m                INSERT INTO competences (nom, requis)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m                VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m                ON CONFLICT (nom) DO NOTHING;\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m            \u001b[39m\u001b[33m\"\"\"\u001b[39m, (competence, requis))\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Insert postes (job positions)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "with psycopg2.connect(\n",
    "    dbname=\"webmining\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ") as conn:\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for comp in annonce[\"competences\"]:\n",
    "        if isinstance(comp, str):\n",
    "            competence = comp\n",
    "            requis = False\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO competences (nom, requis)\n",
    "                VALUES (%s, %s)\n",
    "                ON CONFLICT (nom) DO NOTHING;\n",
    "            \"\"\", (competence, requis))\n",
    "        else:\n",
    "            # Insertion des données dans la table postes\n",
    "            # Insert competences (if not already inserted)\n",
    "            for competence, requis in comp:\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO competences (nom, requis)\n",
    "                    VALUES (%s, %s)\n",
    "                    ON CONFLICT (nom) DO NOTHING;\n",
    "                \"\"\", (competence, requis))\n",
    "\n",
    "    # Insert postes (job positions)\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO annonces (intitule_poste, description, experience, divers, reference)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        RETURNING reference;\n",
    "    \"\"\", (annonce[\"intitule_poste\"], annonce[\"description\"], annonce[\"experience\"], annonce[\"divers\"], annonce[\"reference\"]))\n",
    "\n",
    "    # print(cur.fetchone())\n",
    "    annonce_id = cur.fetchone()[0]\n",
    "    print(annonce_id)\n",
    "\n",
    "    for comp in annonce[\"competences\"]:\n",
    "        if isinstance(comp, str):\n",
    "            competence = comp\n",
    "            cur.execute(\"\"\"\n",
    "            INSERT INTO annonce_competences (annonce_reference, competence_id)\n",
    "            SELECT %s, id FROM competences WHERE nom = %s;\n",
    "            \"\"\", (annonce_id, competence))\n",
    "        else:\n",
    "            for competence, requis in annonce[\"competences\"]:\n",
    "                # Insert relationship into the junction table\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO annonce_competences (annonce_reference, competence_id)\n",
    "                    SELECT %s, id FROM competences WHERE nom = %s;\n",
    "                \"\"\", (annonce_id, competence))\n",
    "\n",
    "\n",
    "    # Validation des modifications et fermeture de la connexion\n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Actualiser régulièrement ses connaissances', True),\n",
       " ('Adapter les méthodes de travail à la réglementation locale', True),\n",
       " ('Algorithmique', True),\n",
       " (\"Analyser / traiter l'information à des fins d'anticipation\", True),\n",
       " ('Analyser, exploiter, structurer des données', True),\n",
       " ('Anglais technique', True),\n",
       " ('Business Intelligence (BI) / Informatique décisionnelle', True),\n",
       " ('Collaborer dans un groupe pour réaliser un projet', True),\n",
       " (\"Communiquer à l'écrit de façon appropriée\", True),\n",
       " ('Concevoir et gérer un projet', True),\n",
       " ('Convaincre en argumentant avec un ou plusieurs interlocuteurs (interne et externe)',\n",
       "  True),\n",
       " ('Data engineer', True),\n",
       " ('Définir les solutions de stockage et de structuration des données', True),\n",
       " ('Déploiement de services cloud (cloud computing)', True),\n",
       " (\"Déployer, intégrer un logiciel, un système d'informations, une application\",\n",
       "  True),\n",
       " ('Développer une application en lien avec une base de données', True),\n",
       " ('Enrichir une base de données', True),\n",
       " ('Expliquer et faire respecter les règles et procédures', True),\n",
       " ('Gérer et maitriser des bases de données (SQL/NoSQL)', True),\n",
       " ('Gérer une architecture technique', True),\n",
       " ('Identifier ses axes de progrès', True),\n",
       " ('Informatique scientifique et technique', True),\n",
       " (\"Mettre en place des solutions d'amélioration de la performance\", True),\n",
       " ('Modéliser une base de données', True),\n",
       " ('Programmation en Python', True),\n",
       " ('Recueillir et analyser les besoins client', True),\n",
       " ('Réaliser une analyse ou modélisation statistique de données', True),\n",
       " ('Technologies HADOOP', True),\n",
       " ('Technologies SPARK (Framework)', True),\n",
       " (\"Tester un logiciel, un système d'informations, une application\", True),\n",
       " ('Vérifier la compatibilité des développements produits avec les spécifications',\n",
       "  True),\n",
       " ('Anglais', True),\n",
       " ('B - Véhicule léger', False)]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annonce[\"competences\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
