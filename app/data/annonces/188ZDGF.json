{"intitule_poste": "TAF 2025 - DATA ENGINEER H/F ", "description": "Employeur pr\u00e9sent le 26 et 27 mars au Salon TAF secteur DIGITALENT - NUMERIQUE\n\nNous recrutons un/e DATA ENGINEER H/F  : 5 postes \u00e0 pourvoir sur France enti\u00e8re\n\nMinimum de 3 \u00e0 5 ans d'exp\u00e9rience dans un r\u00f4le similaire de Data Engineer ou dans la gestion de pipelines de donn\u00e9es. \n\nLe/la Data Engineer est responsable de la conception, du d\u00e9veloppement et de la gestion des architectures de donn\u00e9es permettant de collecter, stocker et traiter des donn\u00e9es \u00e0 grande \u00e9chelle. Il/elle travaille en \u00e9troite collaboration avec les Data Scientists, les Data Analysts et les \u00e9quipes m\u00e9tiers pour garantir l'int\u00e9grit\u00e9, la qualit\u00e9 et la disponibilit\u00e9 des donn\u00e9es. Le/la Data Engineer cr\u00e9e des pipelines de donn\u00e9es robustes et efficaces, tout en veillant \u00e0 ce que les syst\u00e8mes de gestion des donn\u00e9es soient performants et \u00e9volutifs. Les missions principales incluent : \n\nConcevoir, d\u00e9velopper et maintenir des pipelines de donn\u00e9es ETL (Extract, Transform, Load) robustes. \nAssurer l'int\u00e9gration des donn\u00e9es provenant de diverses sources (bases de donn\u00e9es, API, fichiers, etc.). \nG\u00e9rer et optimiser les bases de donn\u00e9es relationnelles et non relationnelles (SQL, NoSQL). \nCollaborer avec les \u00e9quipes Data Science et Data Analysis pour assurer la qualit\u00e9 et la disponibilit\u00e9 des donn\u00e9es pour les analyses. \nMettre en place et g\u00e9rer les environnements cloud (AWS, Azure, Google Cloud) pour le stockage et le traitement des donn\u00e9es. \nAssurer la s\u00e9curit\u00e9 et la conformit\u00e9 des donn\u00e9es, notamment en termes de protection et de confidentialit\u00e9. \nG\u00e9rer les flux de donn\u00e9es et veiller \u00e0 la mise \u00e0 jour en temps r\u00e9el des informations critiques. \nTravailler \u00e0 l'optimisation des performances des pipelines et des processus de donn\u00e9es. \nParticiper \u00e0 la d\u00e9finition des meilleures pratiques en mati\u00e8re de gestion des donn\u00e9es et \u00e0 la mise en place d'une gouvernance des donn\u00e9es efficace. \n\n\nMa\u00eetrise des langages de programmation pour le traitement des donn\u00e9es (Python, Java, Scala, etc.). \nExpertise dans les bases de donn\u00e9es relationnelles (MySQL, PostgreSQL) et non relationnelles (MongoDB, Cassandra, etc.). \nExp\u00e9rience avec des outils ETL (Apache Nifi, Talend, Informatica, etc.) et des frameworks Big Data (Hadoop, Spark). \nBonne connaissance des outils de cloud computing (AWS, Azure, Google Cloud). \nConnaissance des syst\u00e8mes de gestion des flux de donn\u00e9es en temps r\u00e9el (Kafka, Apache Flume). \nExp\u00e9rience en gestion de la s\u00e9curit\u00e9 et de la conformit\u00e9 des donn\u00e9es. \nComp\u00e9tences en gestion de version (Git, GitLab). \n\n", "experience": ["3 An(s)", true], "education": ["Bac+5 et plus ou \u00e9quivalents \n", true], "competences": [["Analyser, exploiter, structurer des donn\u00e9es", false], ["Concevoir et g\u00e9rer un projet", false], ["Enrichir une base de donn\u00e9es", false]], "divers": ["Salaire brut : Annuel de 50000.00 Euros \u00e0 70000.00 Euros sur 12 mois"], "reference": "188ZDGF"}